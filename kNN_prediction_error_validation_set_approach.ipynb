{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#N = 20\n",
    "#mu = 0\n",
    "#sigma = 0.6\n",
    "#k=3\n",
    "#\n",
    "#X_train = np.linspace(-4,4,N)\n",
    "#X_train = X_train.reshape(-1,1)\n",
    "#\n",
    "#y_train = np.zeros(N)\n",
    "#y_train = y_train.reshape(-1,1)\n",
    "#\n",
    "#epsilon_train = np.random.normal(mu,sigma,N)\n",
    "#epsilon_train = epsilon_train.reshape(-1,1)\n",
    "#\n",
    "#y_train = X_train*X_train + epsilon_train\n",
    "#\n",
    "#\n",
    "#neigh = KNeighborsRegressor(n_neighbors=k)\n",
    "#neigh.fit(X_train, y_train)\n",
    "#\n",
    "#X_eval = np.linspace(-4,4,1000)\n",
    "#X_eval = X_eval.reshape(-1,1)\n",
    "#\n",
    "#plt.figure()\n",
    "#plt.plot(X_eval,neigh.predict(X_eval), label=\"kNN regression predictor\")\n",
    "#plt.plot(X_eval,X_eval*X_eval, label=\"exact model\")\n",
    "#plt.plot(X_train,y_train, 'rs', markersize=12, label=\"trainin set\")\n",
    "#plt.title(\"kNN regression for model $f(X)=X^2+\\epsilon$ and $k=3$\")\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "\n",
    "mu = 0.0\n",
    "sigma = 1.15\n",
    "N= 51\n",
    "N_train = 40\n",
    "\n",
    "X = np.linspace(-4,4,N)\n",
    "X = X.reshape(-1,1)\n",
    "\t\n",
    "y = np.zeros(N)\n",
    "y = y.reshape(-1,1)\n",
    "\n",
    "epsilon = np.random.normal(mu,sigma,N)\n",
    "epsilon = epsilon.reshape(-1,1)\n",
    "\n",
    "y = X*X + epsilon\n",
    "\n",
    "kMax = 20\n",
    "\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.figure()\n",
    "\n",
    "for s in range(5):\n",
    "\n",
    "\tindices = list(range(N));\n",
    "\n",
    "\tindices_perm = np.random.permutation(indices)\n",
    "\n",
    "\tX_train = X[indices_perm[:N_train]]\n",
    "\ty_train = y[indices_perm[:N_train]]\n",
    "\tX_validate = X[indices_perm[N_train:]]\n",
    "\ty_validate = y[indices_perm[N_train:]]\n",
    "\t\n",
    "\terrors = np.zeros(kMax)\n",
    "\n",
    "\tfor k in range(1,kMax+1):\n",
    "\t\tneigh = KNeighborsRegressor(n_neighbors=k)\n",
    "\t\tneigh.fit(X_train, y_train)\n",
    "\t\ty_prediction = neigh.predict(X_validate)\n",
    "\t\terrors[k-1] = np.sum((y_prediction-y_validate)**2)/len(y_prediction)\n",
    "\n",
    "\tplt.plot(np.linspace(1,kMax,kMax),errors)\n",
    "\n",
    "#print(np.linspace(1,kMax,kMax))\n",
    "#print(errors)\n",
    "#print(biasSqs)\n",
    "#print(variances)\n",
    "#plt.plot(np.linspace(1,kMax,kMax),biasSqs, label=\"squared bias\")\n",
    "#plt.plot(np.linspace(1,kMax,kMax),variances, label=\"variance\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"neighborhood size $k$\")\n",
    "plt.ylabel(\"error computed by validation set approach using $L_2$ loss\")\n",
    "#plt.plot(X_eval,X_eval*X_eval, label=\"exact model\")\n",
    "#plt.plot(X_train,y_train, 'rs', markersize=12, label=\"trainin set\")\n",
    "plt.title(\"influence of different splits on error prediction (kNN regression error)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
