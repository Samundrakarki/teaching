{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#N = 20\n",
    "#mu = 0\n",
    "#sigma = 0.6\n",
    "#k=3\n",
    "#\n",
    "#X_train = np.linspace(-4,4,N)\n",
    "#X_train = X_train.reshape(-1,1)\n",
    "#\n",
    "#y_train = np.zeros(N)\n",
    "#y_train = y_train.reshape(-1,1)\n",
    "#\n",
    "#epsilon_train = np.random.normal(mu,sigma,N)\n",
    "#epsilon_train = epsilon_train.reshape(-1,1)\n",
    "#\n",
    "#y_train = X_train*X_train + epsilon_train\n",
    "#\n",
    "#\n",
    "#neigh = KNeighborsRegressor(n_neighbors=k)\n",
    "#neigh.fit(X_train, y_train)\n",
    "#\n",
    "#X_eval = np.linspace(-4,4,1000)\n",
    "#X_eval = X_eval.reshape(-1,1)\n",
    "#\n",
    "#plt.figure()\n",
    "#plt.plot(X_eval,neigh.predict(X_eval), label=\"kNN regression predictor\")\n",
    "#plt.plot(X_eval,X_eval*X_eval, label=\"exact model\")\n",
    "#plt.plot(X_train,y_train, 'rs', markersize=12, label=\"trainin set\")\n",
    "#plt.title(\"kNN regression for model $f(X)=X^2+\\epsilon$ and $k=3$\")\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "\n",
    "mu = 0.0\n",
    "sigma = 1.15\n",
    "N= 51\n",
    "N_train = 40\n",
    "\n",
    "X = np.linspace(-4,4,N)\n",
    "X = X.reshape(-1,1)\n",
    "\t\n",
    "y = np.zeros(N)\n",
    "y = y.reshape(-1,1)\n",
    "\n",
    "epsilon = np.random.normal(mu,sigma,N)\n",
    "epsilon = epsilon.reshape(-1,1)\n",
    "\n",
    "y = X*X + epsilon\n",
    "\n",
    "kMax = 20\n",
    "\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.figure()\n",
    "\n",
    "for s in range(5):\n",
    "\n",
    "\tindices = list(range(N));\n",
    "\n",
    "\tindices_perm = np.random.permutation(indices)\n",
    "\n",
    "\terrors = np.zeros(kMax)\n",
    "\n",
    "\tfor k in range(1,kMax+1):\n",
    "\n",
    "\t\tcurr_error = 0\n",
    "\n",
    "\t\tfor l in range(N):\t\t\n",
    "\n",
    "\n",
    "\t\t\tX_train = X[indices_perm]\n",
    "\t\t\ty_train = y[indices_perm]\n",
    "\t\t\tX_train = np.delete(X_train,[l])\n",
    "\t\t\ty_train = np.delete(y_train,[l])\n",
    "\t\t\tX_train = X_train.reshape(-1,1)\n",
    "\t\t\ty_train = y_train.reshape(-1,1)\n",
    "\n",
    "\t\t\tX_validate = X[indices_perm[l]]\n",
    "\t\t\ty_validate = y[indices_perm[l]]\n",
    "\t\t\tX_validate=[X_validate]\n",
    "\t\t\ty_validate=[y_validate]\n",
    "\t\t\t\n",
    "\t\t\tneigh = KNeighborsRegressor(n_neighbors=k)\n",
    "\t\t\tneigh.fit(X_train, y_train)\n",
    "\t\t\ty_prediction = neigh.predict(X_validate)\n",
    "\t\t\tcurr_error = curr_error + (y_prediction-y_validate)**2\n",
    "\t\t\n",
    "\t\terrors[k-1] = curr_error/N\n",
    "\n",
    "\tif s>0:\n",
    "\t\tplt.plot(np.linspace(1,kMax,kMax),errors,'r', label=\"_nolegend_\")\n",
    "\telse:\n",
    "\t\tplt.plot(np.linspace(1,kMax,kMax),errors,'r', label=\"leave-one-out CV\")\n",
    "\t\t\n",
    "\n",
    "for s in range(5):\n",
    "\n",
    "\tindices = list(range(N));\n",
    "\n",
    "\tindices_perm = np.random.permutation(indices)\n",
    "\n",
    "\tK = 10\n",
    "\n",
    "\tindices_perm = np.array_split(indices_perm,K);\n",
    "\tindices_perm=np.asarray(indices_perm)\n",
    "\t\n",
    "\terrors = np.zeros(kMax)\n",
    "\n",
    "\tfor k in range(1,kMax+1):\n",
    "\n",
    "\t\tcurr_error = 0\n",
    "\n",
    "\t\tfor l in range(K):\t\t\n",
    "\n",
    "\t\t\tsubset_indices = list(range(K))\n",
    "\t\t\tcurr_subset_index = l\n",
    "\t\t\tsubset_indices.remove(curr_subset_index)\n",
    "\t\n",
    "\t\t\tindices_train = indices_perm[subset_indices]\n",
    "\t\t\tindices_train = np.concatenate(indices_train)\n",
    "\t\t\tindices_validate = indices_perm[curr_subset_index]\n",
    "\n",
    "\t\t\tX_train = X[indices_train]\n",
    "\t\t\ty_train = y[indices_train]\n",
    "\n",
    "\t\t\tX_validate = X[indices_validate]\n",
    "\t\t\ty_validate = y[indices_validate]\n",
    "\n",
    "#\t\t\tprint(len(X_train))\n",
    "#\t\t\tprint(len(X_validate))\n",
    "\t\t\t\n",
    "\t\t\tneigh = KNeighborsRegressor(n_neighbors=k)\n",
    "\t\t\tneigh.fit(X_train, y_train)\n",
    "\t\t\ty_prediction = neigh.predict(X_validate)\n",
    "\t\t\tcurr_error = curr_error + np.sum((y_prediction-y_validate)**2)/len(y_prediction)\n",
    "\t\t\n",
    "\t\terrors[k-1] = (curr_error/K)\n",
    "\n",
    "\tif s>0:\n",
    "\t\tplt.plot(np.linspace(1,kMax,kMax),errors,color='orange', label=\"_nolegend_\")\n",
    "\telse:\n",
    "\t\tplt.plot(np.linspace(1,kMax,kMax),errors,color='orange', label=\"10-fold CV\")\n",
    "\n",
    "\n",
    "\n",
    "for s in range(5):\n",
    "\n",
    "\tindices = list(range(N));\n",
    "\n",
    "\tindices_perm = np.random.permutation(indices)\n",
    "\n",
    "\tX_train = X[indices_perm[:N_train]]\n",
    "\ty_train = y[indices_perm[:N_train]]\n",
    "\tX_validate = X[indices_perm[N_train:]]\n",
    "\ty_validate = y[indices_perm[N_train:]]\n",
    " \n",
    "\terrors = np.zeros(kMax)\n",
    "\n",
    "\tfor k in range(1,kMax+1):\n",
    "\t\tneigh = KNeighborsRegressor(n_neighbors=k)\n",
    "\t\tneigh.fit(X_train, y_train)\n",
    "\t\ty_prediction = neigh.predict(X_validate)\n",
    "\t\terrors[k-1] = np.sum((y_prediction-y_validate)**2)/len(y_prediction)\n",
    "\n",
    "\tif s>0:\n",
    "\t\tplt.plot(np.linspace(1,kMax,kMax),errors,'k',alpha=0.2,label=\"_nolegend_\")\n",
    "\telse:\n",
    "\t\tplt.plot(np.linspace(1,kMax,kMax),errors,'k',alpha=0.2,label=\"validation set approach\")\n",
    "\t\n",
    "\n",
    "\n",
    "#print(np.linspace(1,kMax,kMax))\n",
    "#print(errors)\n",
    "#print(biasSqs)\n",
    "#print(variances)\n",
    "#plt.plot(np.linspace(1,kMax,kMax),biasSqs, label=\"squared bias\")\n",
    "#plt.plot(np.linspace(1,kMax,kMax),variances, label=\"variance\")\n",
    "plt.legend()\n",
    "plt.xlim(kMax,1)\n",
    "plt.xlabel(\"neighborhood size $k$\")\n",
    "plt.ylabel(\"error computed by different methods using $L_2$ loss\")\n",
    "#plt.plot(X_eval,X_eval*X_eval, label=\"exact model\")\n",
    "#plt.plot(X_train,y_train, 'rs', markersize=12, label=\"trainin set\")\n",
    "plt.title(\"influence of different splits on error prediction (kNN regression)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
