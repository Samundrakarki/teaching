{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "#N = 20\n",
    "#mu = 0\n",
    "#sigma = 0.6\n",
    "#k=3\n",
    "#\n",
    "#X_train = np.linspace(-4,4,N)\n",
    "#X_train = X_train.reshape(-1,1)\n",
    "#\n",
    "#y_train = np.zeros(N)\n",
    "#y_train = y_train.reshape(-1,1)\n",
    "#\n",
    "#epsilon_train = np.random.normal(mu,sigma,N)\n",
    "#epsilon_train = epsilon_train.reshape(-1,1)\n",
    "#\n",
    "#y_train = X_train*X_train + epsilon_train\n",
    "#\n",
    "#\n",
    "#neigh = KNeighborsRegressor(n_neighbors=k)\n",
    "#neigh.fit(X_train, y_train)\n",
    "#\n",
    "#X_eval = np.linspace(-4,4,1000)\n",
    "#X_eval = X_eval.reshape(-1,1)\n",
    "#\n",
    "#plt.figure()\n",
    "#plt.plot(X_eval,neigh.predict(X_eval), label=\"kNN regression predictor\")\n",
    "#plt.plot(X_eval,X_eval*X_eval, label=\"exact model\")\n",
    "#plt.plot(X_train,y_train, 'rs', markersize=12, label=\"trainin set\")\n",
    "#plt.title(\"kNN regression for model $f(X)=X^2+\\epsilon$ and $k=3$\")\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "N = 97\n",
    "\n",
    "X=np.loadtxt(\"prostate.csv\", skiprows=1, usecols=(1,2,3,4,5,6,7,8))\n",
    "y=np.loadtxt(\"prostate.csv\", skiprows=1, usecols=(9))\n",
    "\n",
    "kMax = 40\n",
    "\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.figure()\n",
    "\n",
    "for s in list([0]):\n",
    "\n",
    "\tindices = list(range(N));\n",
    "\n",
    "\tindices_perm = np.random.permutation(indices)\n",
    "\n",
    "\terrors = np.zeros(kMax)\n",
    "\n",
    "\tfor k in range(1,kMax+1):\n",
    "\n",
    "\t\tcurr_error = 0\n",
    "\n",
    "\t\tfor l in range(N):\t\t\n",
    "\n",
    "\n",
    "\t\t\tX_train = X[indices_perm]\n",
    "\t\t\ty_train = y[indices_perm]\n",
    "\t\t\tX_train = np.delete(X_train,[l],axis=0)\n",
    "\t\t\ty_train = np.delete(y_train,[l],axis=0)\n",
    "\n",
    "\t\t\tX_validate = X[indices_perm[l]]\n",
    "\t\t\ty_validate = y[indices_perm[l]]\n",
    "\t\t\tX_validate=[X_validate]\n",
    "\t\t\ty_validate=[y_validate]\n",
    "\t\t\t\n",
    "\t\t\tneigh = KNeighborsRegressor(n_neighbors=k)\n",
    "\t\t\tneigh.fit(X_train, y_train)\n",
    "\t\t\ty_prediction = neigh.predict(X_validate)\n",
    "\t\t\tcurr_error = curr_error + (y_prediction-y_validate)**2\n",
    "\t\t\n",
    "\t\terrors[k-1] = curr_error/N\n",
    "\n",
    "\tplt.plot(np.linspace(1,kMax,kMax),errors,label=\"kNN reg. (leave-one-out CV)\")\n",
    "\t\t\n",
    "\n",
    "for s in list([0]):\n",
    "\n",
    "\tindices = list(range(N));\n",
    "\n",
    "\tindices_perm = np.random.permutation(indices)\n",
    "\n",
    "\terrors = np.zeros(kMax)\n",
    "\n",
    "\tfor k in range(1,kMax+1):\n",
    "\n",
    "\t\tcurr_error = 0\n",
    "\n",
    "\n",
    "\t\tX_train = X[indices_perm]\n",
    "\t\ty_train = y[indices_perm]\n",
    "\n",
    "\t\tneigh = KNeighborsRegressor(n_neighbors=k)\n",
    "\t\tneigh.fit(X_train, y_train)\n",
    "\t\ty_prediction = neigh.predict(X_train)\n",
    "\t\tcurr_error = np.sum((y_prediction-y_train)**2)\n",
    "\t\t\n",
    "\t\terrors[k-1] = curr_error/N\n",
    "\n",
    "\tplt.plot(np.linspace(1,kMax,kMax),errors,label=\"kNN reg. (training error)\")\n",
    "\t\t\n",
    "\n",
    "\n",
    "curr_error = 0\n",
    "for l in range(N):\t\t\n",
    "\n",
    "\tX_train = X\n",
    "\ty_train = y\n",
    "\tX_train = np.delete(X_train,[l],axis=0)\n",
    "\ty_train = np.delete(y_train,[l],axis=0)\n",
    "\n",
    "\tX_validate = X[l]\n",
    "\ty_validate = y[l]\n",
    "\tX_validate = [X_validate]\n",
    "\ty_validate = [y_validate]\n",
    "\n",
    "\tlin_regr = linear_model.LinearRegression()\n",
    "\tlin_regr.fit(X_train, y_train)\n",
    "\ty_prediction = lin_regr.predict(X_validate)\n",
    "\tcurr_error = curr_error + (y_prediction-y_validate)**2\n",
    "\t\t\n",
    "error_lin = curr_error/N\n",
    "\n",
    "plt.plot(np.linspace(1,kMax,kMax),error_lin*np.ones(kMax),label=\"linear reg. (leave-one-out CV)\")\n",
    "\n",
    "\n",
    "lin_regr = linear_model.LinearRegression()\n",
    "lin_regr.fit(X, y)\n",
    "y_prediction = lin_regr.predict(X)\n",
    "lin_reg_training_error = sum((y_prediction-y)**2)/N\n",
    "\n",
    "plt.plot(np.linspace(1,kMax,kMax),lin_reg_training_error*np.ones(kMax),label=\"linear reg. (training error)\")\n",
    "\n",
    "\n",
    "\n",
    "# for s in range(5):\n",
    "# \n",
    "# \tindices = list(range(N));\n",
    "# \n",
    "# \tindices_perm = np.random.permutation(indices)\n",
    "# \n",
    "# \tK = 10\n",
    "# \n",
    "# \tindices_perm = np.array_split(indices_perm,K);\n",
    "# \tindices_perm=np.asarray(indices_perm)\n",
    "# \t\n",
    "# \terrors = np.zeros(kMax)\n",
    "# \n",
    "# \tfor k in range(1,kMax+1):\n",
    "# \n",
    "# \t\tcurr_error = 0\n",
    "# \n",
    "# \t\tfor l in range(K):\t\t\n",
    "# \n",
    "# \t\t\tsubset_indices = list(range(K))\n",
    "# \t\t\tcurr_subset_index = l\n",
    "# \t\t\tsubset_indices.remove(curr_subset_index)\n",
    "# \t\n",
    "# \t\t\tindices_train = indices_perm[subset_indices]\n",
    "# \t\t\tindices_train = np.concatenate(indices_train)\n",
    "# \t\t\tindices_validate = indices_perm[curr_subset_index]\n",
    "# \n",
    "# \t\t\tX_train = X[indices_train]\n",
    "# \t\t\ty_train = y[indices_train]\n",
    "# \n",
    "# \t\t\tX_validate = X[indices_validate]\n",
    "# \t\t\ty_validate = y[indices_validate]\n",
    "# \n",
    "# #\t\t\tprint(len(X_train))\n",
    "# #\t\t\tprint(len(X_validate))\n",
    "# \t\t\t\n",
    "# \t\t\tneigh = KNeighborsRegressor(n_neighbors=k)\n",
    "# \t\t\tneigh.fit(X_train, y_train)\n",
    "# \t\t\ty_prediction = neigh.predict(X_validate)\n",
    "# \t\t\tcurr_error = curr_error + np.sum((y_prediction-y_validate)**2)/len(y_prediction)\n",
    "# \t\t\n",
    "# \t\terrors[k-1] = (curr_error/K)\n",
    "# \n",
    "# \tif s>0:\n",
    "# \t\tplt.plot(np.linspace(1,kMax,kMax),errors,color='orange', label=\"_nolegend_\")\n",
    "# \telse:\n",
    "# \t\tplt.plot(np.linspace(1,kMax,kMax),errors,color='orange', label=\"10-fold CV\")\n",
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(np.linspace(1,kMax,kMax))\n",
    "#print(errors)\n",
    "#print(biasSqs)\n",
    "#print(variances)\n",
    "#plt.plot(np.linspace(1,kMax,kMax),biasSqs, label=\"squared bias\")\n",
    "#plt.plot(np.linspace(1,kMax,kMax),variances, label=\"variance\")\n",
    "plt.legend()\n",
    "plt.xlim(kMax,1)\n",
    "plt.xlabel(\"neighborhood size $k$ (in kNN)\")\n",
    "plt.ylabel(\"different errors using $L_2$ loss\")\n",
    "#plt.plot(X_eval,X_eval*X_eval, label=\"exact model\")\n",
    "#plt.plot(X_train,y_train, 'rs', markersize=12, label=\"trainin set\")\n",
    "plt.title(\"error analysis for prostate cancer data set\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
